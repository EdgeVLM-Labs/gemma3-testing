tokenizers
sentencepiece
shortuuid
pydantic
markdown2[all]
torch>=2.1.0       
accelerate
peft==0.10.0
bitsandbytes
deepspeed
timm
einops
einops-exts
unsloth        
unsloth_zoo    
opencv-python
opencv-contrib-python
imageio
decord
Pillow          
mmengine
scikit-learn
datasets>=3.4.1,<4.0.0
sacrebleu
evaluate
nltk
sqlitedict
pytablewriter
gradio
gradio_client
requests
httpx
uvicorn
fastapi
loguru
tenacity
hf_transfer
shortuuid
numpy<2.0
wandb
openai==1.54.0
albumentations
opencv-python-headless  