{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605cabce-e404-4892-8883-f507162dc779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting unsloth\n",
      "  Using cached unsloth-2025.12.9-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting unsloth_zoo>=2025.12.7 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.12.7-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.20.1+cu121)\n",
      "Requirement already satisfied: numpy in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (2.2.6)\n",
      "Requirement already satisfied: tqdm in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (7.2.1)\n",
      "Requirement already satisfied: tyro in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (1.0.3)\n",
      "Requirement already satisfied: protobuf in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (6.33.2)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.49.0)\n",
      "Requirement already satisfied: triton>=3.0.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (3.1.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.2.1)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.18.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (0.1.9)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Using cached diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth) (4.55.4)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Using cached trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\n",
      "Requirement already satisfied: anyio in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.7.0)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 (from unsloth)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.2)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.15.0)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (12.0.0)\n",
      "Requirement already satisfied: msgspec in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.20.0)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.13.1.3)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting importlib_metadata (from diffusers->unsloth)\n",
      "  Using cached importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from tyro->unsloth) (4.4.4)\n",
      "Using cached unsloth-2025.12.9-py3-none-any.whl (376 kB)\n",
      "Using cached datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached unsloth_zoo-2025.12.7-py3-none-any.whl (290 kB)\n",
      "Using cached xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
      "Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Using cached diffusers-0.36.0-py3-none-any.whl (4.6 MB)\n",
      "Using cached importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, importlib_metadata, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, tokenizers, diffusers, xformers, transformers, torchvision, datasets, cut_cross_entropy, trl, unsloth_zoo, unsloth\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.1.0\n",
      "\u001b[2K    Uninstalling triton-3.1.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.1.0\n",
      "\u001b[2K  Attempting uninstall: sympy笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 0/25\u001b[0m [triton]\n",
      "   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 0/25\u001b[0m [triton]\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 0/25\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/25\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 3/25\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.1060m \u001b[32m 3/25\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 3/25\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\u001b[0m \u001b[32m 3/25\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 4/25\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\u001b[0m \u001b[32m 4/25\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/25\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106笏≫煤\u001b[0m \u001b[32m 4/25\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54笏≫煤\u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54笏≫煤笏≫煤\u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105 \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.1050m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.1050m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.1050m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\u001b[0m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1笏≫煤\u001b[0m \u001b[32m 8/25\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1笏≫煤笏≫煤\u001b[0m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.1070m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\u001b[0m \u001b[32m10/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.1.0.70笏≫煤笏―u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.1.0.70:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m13/25\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.5.1+cu121笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13/25\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.5.1+cu121:[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14/25\u001b[0m [torch]nn-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.5.1+cu121m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14/25\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: tokenizers\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14/25\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14/25\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14/25\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14/25\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: transformers[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m17/25\u001b[0m [xformers]]]\n",
      "   \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m17/25\u001b[0m [xformers]\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: transformers 4.55.4\n",
      "\u001b[2K    Uninstalling transformers-4.55.4:[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.55.4m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torchvision笏―u001b[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torchvision 0.20.1+cu121笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.20.1+cu121:\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.20.1+cu121笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m18/25\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: datasets笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m19/25\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: datasets 4.4.2m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m19/25\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling datasets-4.4.2:笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m19/25\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.4.2[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m19/25\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: trl笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m20/25\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: trl 0.26.20m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m20/25\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling trl-0.26.2:笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m20/25\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled trl-0.26.2[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m20/25\u001b[0m [datasets]\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m25/25\u001b[0m [unsloth]4/25\u001b[0m [unsloth]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.36.0 importlib_metadata-8.7.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 torchvision-0.24.1 transformers-4.57.3 triton-3.5.1 trl-0.24.0 unsloth-2025.12.9 unsloth_zoo-2025.12.7 xformers-0.0.33.post2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==4.55.4\n",
      "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (2025.11.3)\n",
      "Requirement already satisfied: requests in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.55.4)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from transformers==4.55.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.4) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->transformers==4.55.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->transformers==4.55.4) (2025.11.12)\n",
      "Using cached transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: transformers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[2K    Found existing installation: transformers 4.57.3\n",
      "\u001b[2K    Uninstalling transformers-4.57.3:笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.24.0 requires transformers>=4.56.1, but you have transformers 4.55.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.4 transformers-4.55.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: timm in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from timm) (2.9.1)\n",
      "Requirement already satisfied: torchvision in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from timm) (0.24.1)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torch->timm) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: numpy in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda/envs/gemma3/lib/python3.11/site-packages (from torchvision->timm) (12.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/root/miniconda/envs/gemma3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "\n",
    "%pip install unsloth\n",
    "%pip install transformers==4.55.4\n",
    "%pip install timm\n",
    "import torch; torch._dynamo.config.recompile_limit = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aedf757-aba4-4399-a8c2-87d70ca5e661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "洶･ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.12.9: Fast Gemma3N patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.422 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c438632910294f788ab3f7bbe5c12aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3n-E4B-it\",\n",
    "    dtype = None, # None for auto detection\n",
    "    max_seq_length = 1024, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de998d19-620c-409b-a54f-9bdbcf5570d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "# Helper function for inference\n",
    "def do_gemma_3n_inference(messages, max_new_tokens = 64):\n",
    "    # 1. Prepare inputs\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt = True,\n",
    "        tokenize = True,\n",
    "        return_dict = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 2. Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        temperature = 0.1,\n",
    "        do_sample = True,\n",
    "        # Keep the streamer so you can still watch it work in the notebook\n",
    "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "    )\n",
    "\n",
    "    # 3. Decode only the NEW tokens (the answer)\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    new_tokens = outputs[0][input_length:]\n",
    "    response_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c1d9b0-e6ec-4192-85e7-aa75349d932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_frames_from_path(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extract evenly spaced frames from a video file.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to video file (string or Path object)\n",
    "        num_frames: Number of frames to extract (default: 8)\n",
    "\n",
    "    Returns:\n",
    "        List of PIL Image objects\n",
    "    \"\"\"\n",
    "    video_path = str(video_path)  # Ensure it's a string\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames == 0:\n",
    "        print(f\"Error: Video has 0 frames: {video_path}\")\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    # Calculate the step size (logic from your first source)\n",
    "    step = max(1, total_frames // num_frames)\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame_idx = min(i * step, total_frames - 1)  # Ensure we don't exceed total frames\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert BGR (OpenCV) to RGB (PIL) without rotation\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(img)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < num_frames:\n",
    "        print(f\"Warning: Only extracted {len(frames)}/{num_frames} frames from {video_path}\")\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cb478a-61ef-465a-b064-ca9e2f9c9f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /workspace/gemma3-testing\n",
      "Looking for videos in: /workspace/gemma3-testing/dataset/elbow_plank\n",
      "Will save results to: /workspace/gemma3-testing/outputs/gemma3n-4b_inference_results.csv\n",
      "\n",
      "Found 5 videos. Starting processing...\n",
      "\n",
      "Processing: 00037526.mp4...\n",
      "## Exercise Form Evaluation: Push-up\n",
      "\n",
      "The person in the video is performing a push-up. Here's an evaluation of their form, including mistakes and recommended corrections:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Body Alignment:** The person appears to be maintaining a relatively straight line from head to heels. This is good for engaging the core and preventing injury.\n",
      "* **Hand Placement:** Hands are placed shoulder-width apart, which is a standard and generally safe position for push-ups.\n",
      "* **Elbow Angle:** The elbows are bent at a 90-degree angle, which is a good starting point for the push-up.\n",
      "\n",
      "**Mistakes and Recommended Corrections:**\n",
      "\n",
      "* **Sagging Hips:** The most noticeable issue is that the hips are sagging towards the floor. This indicates a lack of core engagement and can put strain on the lower back. \n",
      "    * **Correction:** Focus on actively engaging the core muscles (drawing the navel towards the spine) throughout the exercise. Imagine squeezing a ball between the lower back and the abdomen. This will help maintain a straight line from head to heels.\n",
      "* **Head Position:** The head is looking down towards the floor, which can strain the neck.\n",
      "    * **Correction:**\n",
      "  笨 Completed\n",
      "\n",
      "Processing: 00010835.mp4...\n",
      "## Evaluation of Exercise Form:\n",
      "\n",
      "The exercise shown appears to be a **forward fold** or **standing forward bend**. Here's an evaluation of the form, including potential mistakes and recommended corrections:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Straight Back (Initially):** The person starts with a relatively straight back, which is a good starting point for a forward fold.\n",
      "* **Hips Engaged (Potentially):** It's difficult to see clearly, but there might be some engagement of the hips as the person bends forward.\n",
      "\n",
      "**Mistakes and Corrections:**\n",
      "\n",
      "1. **Rounded Back:** This is the most significant issue. The person's back is rounding significantly, especially in the upper back and shoulders. \n",
      "    * **Correction:** Focus on hinging at the hips rather than rounding the spine. Imagine pushing your hips back and down while keeping your back as straight as possible. You can also gently reach your arms towards your feet, allowing the torso to fold forward.\n",
      "\n",
      "2. **Neck Strain:** The head is dropped, which can put strain on the neck.\n",
      "    * **Correction:** Keep the neck in line with the spine. Allow the head to hang naturally, rather than dropping forward. You can also gently look towards the floor\n",
      "  笨 Completed\n",
      "\n",
      "Processing: 00011543.mp4...\n",
      "The exercise form shown is a **push-up**. Here's an evaluation of the form, including mistakes and recommended corrections:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Hands Placement:** The hands appear to be placed shoulder-width apart, which is generally correct for a standard push-up.\n",
      "* **Body Alignment (Initial Position):** The body seems to be in a relatively straight line from head to heels in the starting position.\n",
      "\n",
      "**Mistakes and Recommended Corrections:**\n",
      "\n",
      "* **Sagging Hips:** This is the most significant issue. The hips are significantly sagging towards the floor, creating a rounded back. \n",
      "    * **Correction:** Engage the core muscles (imagine pulling your belly button towards your spine). Focus on maintaining a straight line from head to heels throughout the movement. Think about squeezing your glutes.\n",
      "* **Rounded Back:** The sagging hips often lead to a rounded upper back. \n",
      "    * **Correction:** As mentioned above, core engagement is key. Also, actively try to pull your shoulder blades slightly down and back.\n",
      "* **Head Position:** The head appears to be hanging down, which can strain the neck.\n",
      "    * **Correction:** Maintain a neutral neck position, looking slightly ahead of your hands. Avoid letting your\n",
      "  笨 Completed\n",
      "\n",
      "Processing: 00198937.mp4...\n",
      "The exercise form shown in the video appears to be a **push-up**. Here's an evaluation of the form, including mistakes and recommended corrections:\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "* **Body Alignment:** The person's body is generally in a straight line from head to heels. However, there are some inconsistencies.\n",
      "* **Head Position:** The head is hanging low, almost touching the floor. This can strain the neck.\n",
      "* **Elbow Position:** The elbows are flaring out to the sides rather than tucked in closer to the body.\n",
      "* **Hand Placement:** The hands are placed shoulder-width apart, which is generally correct.\n",
      "* **Core Engagement:** It's difficult to fully assess core engagement from the video, but the overall posture suggests some level of engagement.\n",
      "* **Movement:** The video shows the person lowering their chest towards the floor, but the full range of motion isn't always clear.\n",
      "\n",
      "**Mistakes Present:**\n",
      "\n",
      "1. **Excessive Head Droop:** The head is hanging too low, which can put unnecessary strain on the neck muscles.\n",
      "2. **Flaring Elbows:** The elbows are not tucked in, which can put stress on the shoulder joints.\n",
      "3. **Inconsistent Body Alignment\n",
      "  笨 Completed\n",
      "\n",
      "Processing: 00259167.mp4...\n",
      "The exercise shown appears to be a **floor press or push-up variation**. Here's an evaluation of the form, including mistakes and recommended corrections:\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "* **Starting Position:** The individual is on the floor, likely in a plank position or with knees on the ground. \n",
      "* **Hand Placement:** Hands are placed on the floor, slightly wider than shoulder-width apart.\n",
      "* **Body Alignment:** The body appears to be relatively straight from head to heels (or knees).\n",
      "* **Movement:** The individual is lowering their chest towards the floor and then pushing back up.\n",
      "\n",
      "**Potential Mistakes:**\n",
      "\n",
      "* **Elbow Flare:** It's difficult to see clearly, but there's a possibility of the elbows flaring out to the sides during the lowering phase. This can put excessive stress on the shoulder joints.\n",
      "* **Sagging Hips:** The hips might be sagging downwards, which can reduce the effectiveness of the exercise and put strain on the lower back.\n",
      "* **Head Position:** The head might be looking up or down, which can strain the neck.\n",
      "* **Incomplete Range of Motion:** The individual might not be lowering their chest all the way to the floor or pushing up completely.\n",
      "\n",
      "**Recommended\n",
      "  笨 Completed\n",
      "\n",
      "\n",
      "笨 Success! Saved 5 results to /workspace/gemma3-testing/outputs/gemma3n-4b_inference_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set up paths relative to notebook location\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\")) if \"__file__\" in dir() else os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)  # Go up one level from src/\n",
    "video_folder = os.path.join(project_root, \"dataset\", \"elbow_plank\")\n",
    "output_csv = os.path.join(project_root, \"outputs\", \"gemma3n-4b_inference_results.csv\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Looking for videos in: {video_folder}\")\n",
    "print(f\"Will save results to: {output_csv}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Check if video folder exists\n",
    "if not os.path.exists(video_folder):\n",
    "    print(f\"\\n笞ｸ  Warning: Video folder not found: {video_folder}\")\n",
    "    print(\"Please ensure videos are placed in the dataset/videos/ directory\")\n",
    "    print(\"Or update the video_folder path above to point to your videos location\")\n",
    "else:\n",
    "    # Get list of all video files recursively\n",
    "    video_files = []\n",
    "    for root, dirs, files in os.walk(video_folder):\n",
    "        for file in files:\n",
    "            if Path(file).suffix.lower() in ['.mp4', '.mov', '.avi', '.mkv']:\n",
    "                video_files.append(Path(root) / file)\n",
    "\n",
    "    print(f\"\\nFound {len(video_files)} videos. Starting processing...\\n\")\n",
    "\n",
    "    for video_path in video_files:\n",
    "        relative_path = video_path.relative_to(video_folder)\n",
    "        print(f\"Processing: {relative_path}...\")\n",
    "\n",
    "        # 1. Extract the \"Frame Thing\" (8 snapshots)\n",
    "        video_frames = extract_frames_from_path(str(video_path), num_frames=8)\n",
    "\n",
    "        if not video_frames:\n",
    "            print(f\"  笞ｸ  Failed to extract frames from {relative_path}\")\n",
    "            continue\n",
    "\n",
    "        # 2. Build the message\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    *[{\"type\": \"image\", \"image\": img} for img in video_frames],\n",
    "                    {\"type\": \"text\", \"text\": \"Please evaluate the exercise form shown. What mistakes, if any, are present, and what corrections would you recommend?\"}\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # 3. Inference\n",
    "        try:\n",
    "            response = do_gemma_3n_inference(messages, max_new_tokens=256)\n",
    "            results.append([str(relative_path), response])\n",
    "            print(f\"  笨 Completed\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"  笨 Error processing {relative_path}: {e}\\n\")\n",
    "\n",
    "    # Save to CSV\n",
    "    if results:\n",
    "        with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"video_name\", \"model_output\"])\n",
    "            writer.writerows(results)\n",
    "\n",
    "        print(f\"\\n笨 Success! Saved {len(results)} results to {output_csv}\")\n",
    "    else:\n",
    "        print(\"\\n笞ｸ  No results to save. Please check if videos were processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131ee8b-6843-4aa4-9fa5-dd5c2d56a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gemma3)",
   "language": "python",
   "name": "gemma3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
